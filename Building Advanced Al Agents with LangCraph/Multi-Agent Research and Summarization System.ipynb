{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "IxsY7fS39xIa",
        "outputId": "68323782-047e-49ce-ed2b-4c585b8eb9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: What is the latest news on AI?\n",
            "Response: Recent AI advancements focus on improved large language models, better computer vision, and exciting new uses in healthcare and self-driving technology.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Query: Explain Python programming\n",
            "Response: Python is a versatile programming language used for a wide range of applications, including web development, data science, and artificial intelligence.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Query: What is the capital of France?\n",
            "Response: Paris is the capital of France.\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated, List\n",
        "import operator\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import faiss\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Set API keys (replace with your own or set as environment variables)\n",
        "\n",
        "# Initialize Gemini model\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "llm = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# Simulated knowledge base (in-memory FAISS vector store)\n",
        "class KnowledgeBase:\n",
        "    def __init__(self):\n",
        "        self.dimension = 128  # Example dimension for embeddings\n",
        "        self.index = faiss.IndexFlatL2(self.dimension)\n",
        "        self.documents = []\n",
        "\n",
        "    def add_document(self, text):\n",
        "        # Simulate embedding generation (in practice, use an embedding model)\n",
        "        embedding = np.random.rand(self.dimension).astype('float32')\n",
        "        self.index.add(np.array([embedding]))\n",
        "        self.documents.append(text)\n",
        "\n",
        "    def search(self, query, k=1):\n",
        "        # Simulate embedding for query\n",
        "        query_embedding = np.random.rand(self.dimension).astype('float32')\n",
        "        distances, indices = self.index.search(np.array([query_embedding]), k)\n",
        "        return [self.documents[i] for i in indices[0]]\n",
        "\n",
        "# Initialize knowledge base with sample data\n",
        "kb = KnowledgeBase()\n",
        "kb.add_document(\"Python is a versatile programming language used for web development, data science, and AI.\")\n",
        "kb.add_document(\"LangGraph is a framework for building stateful, multi-agent workflows.\")\n",
        "kb.add_document(\"Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data.\")\n",
        "kb.add_document(\"Neural networks are computing systems inspired by biological neural networks.\")\n",
        "\n",
        "# Web search function - using a mock implementation\n",
        "def web_search(query):\n",
        "    \"\"\"\n",
        "    Mock web search function. In production, you would use:\n",
        "    - Tavily API with a valid key\n",
        "    - Google Search API\n",
        "    - Bing Search API\n",
        "    - Or any other search service\n",
        "    \"\"\"\n",
        "    # Mock responses for different queries\n",
        "    mock_responses = {\n",
        "        \"latest news ai\": \"Recent AI developments include advances in large language models, improved computer vision capabilities, and new applications in healthcare and autonomous systems.\",\n",
        "        \"current ai\": \"Current AI trends focus on generative AI, multimodal models, and responsible AI development practices.\",\n",
        "        \"latest ai\": \"Latest AI news includes breakthrough in quantum-AI hybrid systems, new safety regulations, and expanded AI adoption across industries.\"\n",
        "    }\n",
        "\n",
        "    # Simple keyword matching for mock response\n",
        "    query_lower = query.lower()\n",
        "    for key, response in mock_responses.items():\n",
        "        if any(keyword in query_lower for keyword in key.split()):\n",
        "            return response\n",
        "\n",
        "    return f\"Mock web search result for: {query}. This would contain real-time information from the internet.\"\n",
        "\n",
        "# Alternative: Real web search using requests (free but basic)\n",
        "def simple_web_search(query):\n",
        "    \"\"\"\n",
        "    Simple web search using requests - this is a basic implementation\n",
        "    For production, use proper search APIs\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # This is a simplified example - in practice, you'd use proper search APIs\n",
        "        return f\"Web search functionality would provide real-time results for: {query}\"\n",
        "    except Exception as e:\n",
        "        return f\"Web search temporarily unavailable: {str(e)}\"\n",
        "\n",
        "# State definition for LangGraph\n",
        "class AgentState(TypedDict):\n",
        "    query: str\n",
        "    messages: Annotated[List[dict], operator.add]\n",
        "    route: str\n",
        "    response: str\n",
        "\n",
        "# Router Agent\n",
        "def router_agent(state: AgentState) -> AgentState:\n",
        "    query = state[\"query\"]\n",
        "    prompt = f\"\"\"\n",
        "    Determine if the query requires web search, RAG, or LLM reasoning.\n",
        "    Return 'web' if the query contains 'latest', 'current', 'recent', or 'news'.\n",
        "    Return 'rag' if it relates to programming, AI concepts, or technical topics.\n",
        "    Otherwise return 'llm'.\n",
        "\n",
        "    Query: {query}\n",
        "\n",
        "    Respond with only one word: web, rag, or llm\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = llm.generate_content(prompt)\n",
        "        route = response.text.strip().lower()\n",
        "        # Ensure route is valid\n",
        "        if route not in ['web', 'rag', 'llm']:\n",
        "            route = 'llm'  # Default fallback\n",
        "    except Exception as e:\n",
        "        print(f\"Router error: {e}\")\n",
        "        route = 'llm'  # Default fallback\n",
        "\n",
        "    return {\"route\": route, \"messages\": [{\"role\": \"router\", \"content\": f\"Routed to {route}\"}]}\n",
        "\n",
        "# Web Research Agent\n",
        "def web_research_agent(state: AgentState) -> AgentState:\n",
        "    query = state[\"query\"]\n",
        "    try:\n",
        "        result = web_search(query)\n",
        "    except Exception as e:\n",
        "        result = f\"Web search encountered an error: {str(e)}\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [{\"role\": \"web_research\", \"content\": result}],\n",
        "        \"response\": result\n",
        "    }\n",
        "\n",
        "# RAG Agent\n",
        "def rag_agent(state: AgentState) -> AgentState:\n",
        "    query = state[\"query\"]\n",
        "    try:\n",
        "        results = kb.search(query, k=1)\n",
        "        result = results[0] if results else \"No relevant data found in knowledge base.\"\n",
        "    except Exception as e:\n",
        "        result = f\"RAG search encountered an error: {str(e)}\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [{\"role\": \"rag\", \"content\": result}],\n",
        "        \"response\": result\n",
        "    }\n",
        "\n",
        "# LLM Agent\n",
        "def llm_agent(state: AgentState) -> AgentState:\n",
        "    query = state[\"query\"]\n",
        "    prompt = f\"Answer the following query concisely and accurately: {query}\"\n",
        "\n",
        "    try:\n",
        "        response = llm.generate_content(prompt)\n",
        "        result = response.text\n",
        "    except Exception as e:\n",
        "        result = f\"LLM encountered an error: {str(e)}\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [{\"role\": \"llm\", \"content\": result}],\n",
        "        \"response\": result\n",
        "    }\n",
        "\n",
        "# Summarization Agent\n",
        "def summarization_agent(state: AgentState) -> AgentState:\n",
        "    prompt = f\"\"\"\n",
        "    Summarize the following information into a concise, helpful response for the user:\n",
        "\n",
        "    Information: {state['response']}\n",
        "    Original Query: {state['query']}\n",
        "\n",
        "    Provide a clear, direct answer that addresses the user's question.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = llm.generate_content(prompt)\n",
        "        result = response.text\n",
        "    except Exception as e:\n",
        "        result = f\"Summarization encountered an error: {str(e)}\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [{\"role\": \"summarizer\", \"content\": result}],\n",
        "        \"response\": result\n",
        "    }\n",
        "\n",
        "# Define LangGraph workflow\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"router\", router_agent)\n",
        "workflow.add_node(\"web_research\", web_research_agent)\n",
        "workflow.add_node(\"rag\", rag_agent)\n",
        "workflow.add_node(\"llm\", llm_agent)\n",
        "workflow.add_node(\"summarizer\", summarization_agent)\n",
        "\n",
        "# Define edges\n",
        "workflow.set_entry_point(\"router\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    lambda state: state[\"route\"],\n",
        "    {\n",
        "        \"web\": \"web_research\",\n",
        "        \"rag\": \"rag\",\n",
        "        \"llm\": \"llm\"\n",
        "    }\n",
        ")\n",
        "workflow.add_edge(\"web_research\", \"summarizer\")\n",
        "workflow.add_edge(\"rag\", \"summarizer\")\n",
        "workflow.add_edge(\"llm\", \"summarizer\")\n",
        "workflow.add_edge(\"summarizer\", END)\n",
        "\n",
        "# Compile the graph\n",
        "graph = workflow.compile()\n",
        "\n",
        "# Test the system\n",
        "def run_query(query):\n",
        "    try:\n",
        "        result = graph.invoke({\"query\": query, \"messages\": [], \"route\": \"\", \"response\": \"\"})\n",
        "        return result[\"response\"]\n",
        "    except Exception as e:\n",
        "        return f\"Error processing query: {str(e)}\"\n",
        "\n",
        "# Example queries\n",
        "if __name__ == \"__main__\":\n",
        "    queries = [\n",
        "        \"What is the latest news on AI?\",\n",
        "        \"Explain Python programming\",\n",
        "        \"What is the capital of France?\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(f\"\\nQuery: {query}\")\n",
        "        print(f\"Response: {run_query(query)}\")\n",
        "        print(\"-\" * 50)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
